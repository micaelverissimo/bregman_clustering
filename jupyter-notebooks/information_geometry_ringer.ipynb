{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cluster_algorithms import base_kmeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_path = '../data_files/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97/'\n",
    "file_name       = 'data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97_et0_eta0.npz'\n",
    "\n",
    "plots_path      = '../clustering_plots/'\n",
    "my_seed         = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subplot_axes(ax,rect,axisbg='w'):\n",
    "    fig = plt.gcf()\n",
    "    box = ax.get_position()\n",
    "    width = box.width\n",
    "    height = box.height\n",
    "    inax_position  = ax.transAxes.transform(rect[0:2])\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    infig_position = transFigure.transform(inax_position)    \n",
    "    x = infig_position[0]\n",
    "    y = infig_position[1]\n",
    "    width *= rect[2]\n",
    "    height *= rect[3]  # <= Typo was here\n",
    "    subax = fig.add_axes([x,y,width,height],facecolor=axisbg)\n",
    "    x_labelsize = subax.get_xticklabels()[0].get_size()\n",
    "    y_labelsize = subax.get_yticklabels()[0].get_size()\n",
    "    x_labelsize = rect[2]*0.5\n",
    "    y_labelsize = rect[3]*0.5\n",
    "    #subax.xaxis.set_tick_params(labelsize=x_labelsize)\n",
    "    #subax.yaxis.set_tick_params(labelsize=y_labelsize)\n",
    "    return subax\n",
    "\n",
    "def plot_div_evo(al_object, breg_div, tag, path=plots_path):\n",
    "    plt.figure(figsize=(10,8))    \n",
    "    ax = plt.gca()\n",
    "    ax.plot(range(al_object.get_last_iter()), al_object.get_sum_total_div(), '--o', c='g')\n",
    "    ax.set_title('Total sum of the %s divergence' %(breg_div), fontsize=18)\n",
    "    ax.set_ylabel(r'$D_{\\phi}[C: D]$', fontsize=10)\n",
    "    ax.set_xlabel(r'Iteractions', fontsize=10)\n",
    "    ax.set_xticks(np.arange(1, al_object.get_last_iter()+ 1))\n",
    "    plt.grid()\n",
    "    ax2 = add_subplot_axes(ax, rect=[.3, .3, .6, .6])\n",
    "    ax2.plot(range(al_object.get_last_iter()), al_object.get_sum_total_div(), '--o', c='g')\n",
    "    ax2.set_ylabel(r'$D_{\\phi}[C: D]$', fontsize=15)\n",
    "    ax2.set_xlabel(r'Iteractions', fontsize=15)\n",
    "    #ax2.set_xticks(np.arange(1, al_object.get_last_iter()+ 1))\n",
    "    ax2.set_xlim([0, 8])\n",
    "    ax2.grid()\n",
    "    plt.savefig(path+'sum_total_divergence_ev_'+tag, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "def plot_voronoi2D_diagram(al_object, X, classes, divergence, tag, path=plots_path):\n",
    "    \n",
    "    centers = al_object.get_centroids()\n",
    "    # Get the Voronoi diagrams\n",
    "    vor = Voronoi(centers)\n",
    "    ax_lim = [np.min(X, axis=0), np.max(X, axis=0)]\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(10,8))\n",
    "    # Draw data using target to colorize them\n",
    "    dict_label = {\n",
    "        0 : ('red','Background'),\n",
    "        1 : ('blue','Signal')\n",
    "    }\n",
    "    for i in np.unique(classes):\n",
    "        axes.scatter(X[classes==i, 0], X[classes==i, 1], c=dict_label[i][0],\n",
    "                     edgecolor='k', s=35, alpha=.5, label=dict_label[i][1])\n",
    "    # Draw the centroids\n",
    "    axes.plot(centers[:,0], centers[:,1], '^', c='black', markersize=15, label='Final Centroids')\n",
    "    # Draw voronoi\n",
    "    voronoi_plot_2d(vor, ax=axes, line_colors='darkorange', line_width=3, show_points=False, show_vertices=True)\n",
    "    plt.title('Obtained Clusters for %s divergence' %(divergence), fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best', fontsize='x-large')\n",
    "    plt.xlim([ax_lim[0][0], ax_lim[1][0]])\n",
    "    plt.ylim([ax_lim[0][1], ax_lim[1][1]])\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.xlabel(r'$\\langle\\mu\\rangle$', fontsize=15)\n",
    "    plt.ylabel(r'$E_T$', fontsize=13)\n",
    "    plt.savefig(path+'voronoi_diagram_'+tag, dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'etBins', 'etaBins', 'etBinIdx', 'etaBinIdx', 'data', 'target'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpsi_data = dict(np.load(data_files_path+file_name))\n",
    "jpsi_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avgmu', 'L2Calo_ring_0', 'L2Calo_ring_1', 'L2Calo_ring_2', 'L2Calo_ring_3', 'L2Calo_ring_4', 'L2Calo_ring_5', 'L2Calo_ring_6', 'L2Calo_ring_7', 'L2Calo_ring_8', 'L2Calo_ring_9', 'L2Calo_ring_10', 'L2Calo_ring_11', 'L2Calo_ring_12', 'L2Calo_ring_13', 'L2Calo_ring_14', 'L2Calo_ring_15', 'L2Calo_ring_16', 'L2Calo_ring_17', 'L2Calo_ring_18', 'L2Calo_ring_19', 'L2Calo_ring_20', 'L2Calo_ring_21', 'L2Calo_ring_22', 'L2Calo_ring_23', 'L2Calo_ring_24', 'L2Calo_ring_25', 'L2Calo_ring_26', 'L2Calo_ring_27', 'L2Calo_ring_28', 'L2Calo_ring_29', 'L2Calo_ring_30', 'L2Calo_ring_31', 'L2Calo_ring_32', 'L2Calo_ring_33', 'L2Calo_ring_34', 'L2Calo_ring_35', 'L2Calo_ring_36', 'L2Calo_ring_37', 'L2Calo_ring_38', 'L2Calo_ring_39', 'L2Calo_ring_40', 'L2Calo_ring_41', 'L2Calo_ring_42', 'L2Calo_ring_43', 'L2Calo_ring_44', 'L2Calo_ring_45', 'L2Calo_ring_46', 'L2Calo_ring_47', 'L2Calo_ring_48', 'L2Calo_ring_49', 'L2Calo_ring_50', 'L2Calo_ring_51', 'L2Calo_ring_52', 'L2Calo_ring_53', 'L2Calo_ring_54', 'L2Calo_ring_55', 'L2Calo_ring_56', 'L2Calo_ring_57', 'L2Calo_ring_58', 'L2Calo_ring_59', 'L2Calo_ring_60', 'L2Calo_ring_61', 'L2Calo_ring_62', 'L2Calo_ring_63', 'L2Calo_ring_64', 'L2Calo_ring_65', 'L2Calo_ring_66', 'L2Calo_ring_67', 'L2Calo_ring_68', 'L2Calo_ring_69', 'L2Calo_ring_70', 'L2Calo_ring_71', 'L2Calo_ring_72', 'L2Calo_ring_73', 'L2Calo_ring_74', 'L2Calo_ring_75', 'L2Calo_ring_76', 'L2Calo_ring_77', 'L2Calo_ring_78', 'L2Calo_ring_79', 'L2Calo_ring_80', 'L2Calo_ring_81', 'L2Calo_ring_82', 'L2Calo_ring_83', 'L2Calo_ring_84', 'L2Calo_ring_85', 'L2Calo_ring_86', 'L2Calo_ring_87', 'L2Calo_ring_88', 'L2Calo_ring_89', 'L2Calo_ring_90', 'L2Calo_ring_91', 'L2Calo_ring_92', 'L2Calo_ring_93', 'L2Calo_ring_94', 'L2Calo_ring_95', 'L2Calo_ring_96', 'L2Calo_ring_97', 'L2Calo_ring_98', 'L2Calo_ring_99', 'L2Calo_et', 'L2Calo_eta', 'L2Calo_phi', 'L2Calo_reta', 'L2Calo_eratio', 'L2Calo_f1', 'el_lhtight', 'el_lhmedium', 'el_lhloose', 'el_lhvloose', 'et', 'eta', 'phi', 'eratio', 'reta', 'rphi', 'f1', 'f3', 'rhad', 'rhad1', 'wtots1', 'weta1', 'weta2', 'e277', 'deltaE', 'T0HLTElectronT2CaloTight', 'T0HLTElectronT2CaloMedium', 'T0HLTElectronT2CaloLoose', 'T0HLTElectronT2CaloVLoose', 'HLT__isLHTight', 'HLT__isLHMedium', 'HLT__isLHLoose', 'HLT__isLHVLoose']\n"
     ]
    }
   ],
   "source": [
    "list_of_features = list(jpsi_data['features'])\n",
    "print(list_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_indexes = [list_of_features.index('avgmu'),\n",
    "               list_of_features.index('L2Calo_et'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233397, 2)\n"
     ]
    }
   ],
   "source": [
    "data_      = jpsi_data['data'][:, var_indexes]\n",
    "my_filter  = (data_[:,0] <= 80)\n",
    "sgn_filter = jpsi_data['target'][my_filter]==1\n",
    "bkg_filter = jpsi_data['target'][my_filter]==0\n",
    "data_      = data_[my_filter,:]\n",
    "y          = jpsi_data['target'][my_filter]\n",
    "print(data_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_choices_filter = np.random.choice(data_[sgn_filter].shape[0], size=800)\n",
    "bkg_choices_filter = np.random.choice(data_[bkg_filter].shape[0], size=800)\n",
    "choices_filter     = np.concatenate((sgn_choices_filter,bkg_choices_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2)\n"
     ]
    }
   ],
   "source": [
    "data_ = data_[choices_filter]\n",
    "y     = jpsi_data['target'][choices_filter]\n",
    "print(data_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeV = 1e3\n",
    "epsilon = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_[:, 1] = data_[:, 1]/GeV\n",
    "#data_[data_[:,0] == 0, 0] = data_[data_[:,0] == 0, 0] + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [3, 4, 5]\n",
    "n_folds    = 10\n",
    "divs       = ['euclidean', 'exp', 'itakura-saito', 'gen_kl']#, 'gen_kls', 'gen_js']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_measures = {\n",
    "    'silhouette_score'        : silhouette_score,\n",
    "    'davies_bouldin_score'    : davies_bouldin_score,\n",
    "    'calinski_harabasz_score' : calinski_harabasz_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=n_folds, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVO = list(kf.split(data_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n"
     ]
    }
   ],
   "source": [
    "for idiv in divs:\n",
    "    cv_dict[idiv] = {}\n",
    "    for idx, ifold in enumerate(CVO):\n",
    "        trn_id, tst_id = ifold\n",
    "        scaler         = MinMaxScaler(feature_range=(epsilon, 1))\n",
    "        scaler.fit(data_[trn_id])\n",
    "        norm_data      = scaler.transform(data_)\n",
    "        cv_dict[idiv][idx] = {}\n",
    "        for icluster in n_clusters:\n",
    "            #print('Clustering with %i clusters using %s divergence in %i Fold...' %(icluster, idiv, idx))\n",
    "            cv_dict[idiv][idx][icluster] = {}\n",
    "            kmeans = base_kmeans(n_clusters=icluster)\n",
    "            kmeans.fit(norm_data, n_iter=50, tol=1e-3, breg_div=idiv)\n",
    "            plot_div_evo(kmeans, breg_div=idiv, tag='%s_%i_fold_%i_cluster' %(idiv, idx, icluster))\n",
    "            plot_voronoi2D_diagram(kmeans, X=norm_data, classes=y, divergence=idiv,\n",
    "                                   tag='%s_%i_fold_%i_cluster' %(idiv, idx, icluster))\n",
    "            predicted_labels = kmeans.predict_cluster(norm_data[tst_id])\n",
    "            for imeasure in cluster_measures.keys():\n",
    "                cv_dict[idiv][idx][icluster][imeasure] = cluster_measures[imeasure](norm_data[tst_id],\n",
    "                                                                                    predicted_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cluster_dict = {\n",
    "    'bregman_divergence'      : [],\n",
    "    'n_cluster'               : [],\n",
    "    'silhouette_score'        : [],\n",
    "    'davies_bouldin_score'    : [],\n",
    "    'calinski_harabasz_score' : [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idiv in cv_dict.keys():\n",
    "    for ifold in cv_dict[idiv].keys():\n",
    "        for icluster in cv_dict[idiv][ifold].keys():\n",
    "            info_cluster_dict['bregman_divergence'].append(idiv)\n",
    "            info_cluster_dict['n_cluster'].append(icluster)\n",
    "            for jmeasure in cluster_measures.keys():\n",
    "                info_cluster_dict[jmeasure].append(cv_dict[idiv][ifold][icluster][jmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_df = pd.DataFrame(info_cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_measure = list(cluster_measures.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bregman_divergence</th>\n",
       "      <th>n_cluster</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>davies_bouldin_score</th>\n",
       "      <th>calinski_harabasz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>3</td>\n",
       "      <td>0.335935</td>\n",
       "      <td>0.944799</td>\n",
       "      <td>147.101728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300294</td>\n",
       "      <td>1.126682</td>\n",
       "      <td>134.131398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>0.329511</td>\n",
       "      <td>0.885940</td>\n",
       "      <td>138.486358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>3</td>\n",
       "      <td>0.391564</td>\n",
       "      <td>0.950608</td>\n",
       "      <td>158.138321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>4</td>\n",
       "      <td>0.304507</td>\n",
       "      <td>1.169190</td>\n",
       "      <td>139.155629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bregman_divergence  n_cluster  silhouette_score  davies_bouldin_score  \\\n",
       "0          euclidean          3          0.335935              0.944799   \n",
       "1          euclidean          4          0.300294              1.126682   \n",
       "2          euclidean          5          0.329511              0.885940   \n",
       "3          euclidean          3          0.391564              0.950608   \n",
       "4          euclidean          4          0.304507              1.169190   \n",
       "\n",
       "   calinski_harabasz_score  \n",
       "0               147.101728  \n",
       "1               134.131398  \n",
       "2               138.486358  \n",
       "3               158.138321  \n",
       "4               139.155629  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table = clus_df.groupby(['bregman_divergence', 'n_cluster'])[my_measure].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">silhouette_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">davies_bouldin_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">calinski_harabasz_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bregman_divergence</th>\n",
       "      <th>n_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">euclidean</th>\n",
       "      <th>3</th>\n",
       "      <td>0.352291</td>\n",
       "      <td>0.026463</td>\n",
       "      <td>0.987560</td>\n",
       "      <td>0.090893</td>\n",
       "      <td>129.621501</td>\n",
       "      <td>20.290208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.313657</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>1.011913</td>\n",
       "      <td>0.101014</td>\n",
       "      <td>121.555708</td>\n",
       "      <td>16.822804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.322835</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>0.907166</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>126.224371</td>\n",
       "      <td>13.608467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">exp</th>\n",
       "      <th>3</th>\n",
       "      <td>0.349739</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>1.000536</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>129.299092</td>\n",
       "      <td>19.564928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321949</td>\n",
       "      <td>0.025290</td>\n",
       "      <td>0.986006</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>120.128372</td>\n",
       "      <td>17.238963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.332213</td>\n",
       "      <td>0.015048</td>\n",
       "      <td>0.894387</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>125.607615</td>\n",
       "      <td>13.247866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gen_kl</th>\n",
       "      <th>3</th>\n",
       "      <td>0.354339</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>1.007929</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>127.958620</td>\n",
       "      <td>19.646539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309102</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>1.014581</td>\n",
       "      <td>0.039595</td>\n",
       "      <td>118.375744</td>\n",
       "      <td>18.216333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.311603</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.973315</td>\n",
       "      <td>0.047848</td>\n",
       "      <td>119.324236</td>\n",
       "      <td>17.615023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">itakura-saito</th>\n",
       "      <th>3</th>\n",
       "      <td>0.342100</td>\n",
       "      <td>0.032462</td>\n",
       "      <td>1.076699</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>113.081859</td>\n",
       "      <td>23.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.029061</td>\n",
       "      <td>1.098582</td>\n",
       "      <td>0.119870</td>\n",
       "      <td>102.307193</td>\n",
       "      <td>15.757096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.301276</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>1.025771</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>104.199398</td>\n",
       "      <td>16.120672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             silhouette_score           davies_bouldin_score  \\\n",
       "                                         mean       std                 mean   \n",
       "bregman_divergence n_cluster                                                   \n",
       "euclidean          3                 0.352291  0.026463             0.987560   \n",
       "                   4                 0.313657  0.017839             1.011913   \n",
       "                   5                 0.322835  0.019858             0.907166   \n",
       "exp                3                 0.349739  0.027134             1.000536   \n",
       "                   4                 0.321949  0.025290             0.986006   \n",
       "                   5                 0.332213  0.015048             0.894387   \n",
       "gen_kl             3                 0.354339  0.032294             1.007929   \n",
       "                   4                 0.309102  0.029561             1.014581   \n",
       "                   5                 0.311603  0.021565             0.973315   \n",
       "itakura-saito      3                 0.342100  0.032462             1.076699   \n",
       "                   4                 0.300809  0.029061             1.098582   \n",
       "                   5                 0.301276  0.030773             1.025771   \n",
       "\n",
       "                                       calinski_harabasz_score             \n",
       "                                   std                    mean        std  \n",
       "bregman_divergence n_cluster                                               \n",
       "euclidean          3          0.090893              129.621501  20.290208  \n",
       "                   4          0.101014              121.555708  16.822804  \n",
       "                   5          0.044670              126.224371  13.608467  \n",
       "exp                3          0.082581              129.299092  19.564928  \n",
       "                   4          0.085164              120.128372  17.238963  \n",
       "                   5          0.029217              125.607615  13.247866  \n",
       "gen_kl             3          0.052846              127.958620  19.646539  \n",
       "                   4          0.039595              118.375744  18.216333  \n",
       "                   5          0.047848              119.324236  17.615023  \n",
       "itakura-saito      3          0.083672              113.081859  23.006116  \n",
       "                   4          0.119870              102.307193  15.757096  \n",
       "                   5          0.026999              104.199398  16.120672  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">silhouette_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">davies_bouldin_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">calinski_harabasz_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bregman_divergence</th>\n",
       "      <th>n_cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">euclidean</th>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>129.62</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>121.56</td>\n",
       "      <td>16.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.04</td>\n",
       "      <td>126.22</td>\n",
       "      <td>13.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">exp</th>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>129.30</td>\n",
       "      <td>19.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>120.13</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.03</td>\n",
       "      <td>125.61</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gen_kl</th>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>127.96</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>118.38</td>\n",
       "      <td>18.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>119.32</td>\n",
       "      <td>17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">itakura-saito</th>\n",
       "      <th>3</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>113.08</td>\n",
       "      <td>23.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>102.31</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>104.20</td>\n",
       "      <td>16.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             silhouette_score       davies_bouldin_score  \\\n",
       "                                         mean   std                 mean   \n",
       "bregman_divergence n_cluster                                               \n",
       "euclidean          3                     0.35  0.03                 0.99   \n",
       "                   4                     0.31  0.02                 1.01   \n",
       "                   5                     0.32  0.02                 0.91   \n",
       "exp                3                     0.35  0.03                 1.00   \n",
       "                   4                     0.32  0.03                 0.99   \n",
       "                   5                     0.33  0.02                 0.89   \n",
       "gen_kl             3                     0.35  0.03                 1.01   \n",
       "                   4                     0.31  0.03                 1.01   \n",
       "                   5                     0.31  0.02                 0.97   \n",
       "itakura-saito      3                     0.34  0.03                 1.08   \n",
       "                   4                     0.30  0.03                 1.10   \n",
       "                   5                     0.30  0.03                 1.03   \n",
       "\n",
       "                                   calinski_harabasz_score         \n",
       "                               std                    mean    std  \n",
       "bregman_divergence n_cluster                                       \n",
       "euclidean          3          0.09                  129.62  20.29  \n",
       "                   4          0.10                  121.56  16.82  \n",
       "                   5          0.04                  126.22  13.61  \n",
       "exp                3          0.08                  129.30  19.56  \n",
       "                   4          0.09                  120.13  17.24  \n",
       "                   5          0.03                  125.61  13.25  \n",
       "gen_kl             3          0.05                  127.96  19.65  \n",
       "                   4          0.04                  118.38  18.22  \n",
       "                   5          0.05                  119.32  17.62  \n",
       "itakura-saito      3          0.08                  113.08  23.01  \n",
       "                   4          0.12                  102.31  15.76  \n",
       "                   5          0.03                  104.20  16.12  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As melhores divergências foram a Euclidiana e a Exponencial;\n",
    "* Itakura-saito obteve os piores resultados em todas os índices;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table.round(2).to_excel('../data_files/clusterization_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n",
      "The conversion criteria was reached... Stopping!\n"
     ]
    }
   ],
   "source": [
    "scaler         = MinMaxScaler(feature_range=(epsilon, 1))\n",
    "norm_data      = scaler.fit_transform(data_)\n",
    "icluster = 3\n",
    "for idiv in divs:\n",
    "    kmeans = base_kmeans(n_clusters=icluster)\n",
    "    kmeans.fit(norm_data, n_iter=50, tol=1e-3, breg_div=idiv)\n",
    "    plot_div_evo(kmeans, breg_div=idiv, tag='%s_%i_cluster_operation' %(idiv, icluster))\n",
    "    plot_voronoi2D_diagram(kmeans, X=norm_data, classes=y, divergence=idiv,\n",
    "                                       tag='%s_%i_cluster_operation' %(idiv, icluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
